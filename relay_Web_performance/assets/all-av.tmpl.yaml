---
apiVersion: v1
kind: Namespace
metadata:
  name: demo
---
# =========================
# Web (Flask) はそのまま
# =========================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
  namespace: demo
spec:
  replicas: 2
  selector: { matchLabels: { app: web } }
  template:
    metadata: { labels: { app: web } }
    spec:
      nodeSelector:
        node-purpose: web
      tolerations:
        - { key: "node-role.kubernetes.io/control-plane", operator: "Exists", effect: "NoSchedule" }
        - { key: "node-role.kubernetes.io/master",        operator: "Exists", effect: "NoSchedule" }
      containers:
        - name: web
          image: ${WEB_IMAGE}
          imagePullPolicy: Always
          ports: [ { containerPort: 8080 } ]
          env: [ { name: PYTHONUNBUFFERED, value: "1" } ]
          readinessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 3
            periodSeconds: 5
          livenessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            requests: { cpu: "50m",  memory: "64Mi" }
            limits:   { cpu: "500m", memory: "256Mi" }
---
apiVersion: v1
kind: Service
metadata:
  name: web
  namespace: demo
spec:
  selector: { app: web }
  type: ClusterIP
  ports:
    - { name: http, port: 8080, targetPort: 8080 }
---
# ==========================================
# OpenResty（独自CPUチェック付き）Config
# ==========================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: cpu-proxy-conf
  namespace: demo
data:
  nginx.conf: |
    # “体感”を安定させるためワーカーは 1 に固定（同時チェックを作らない）
    worker_processes 1;
    events { worker_connections 1024; }
    http {
      lua_socket_log_errors on;
      client_max_body_size 100m;
      client_body_buffer_size 8m;
      sendfile on; tcp_nopush on;
      gzip off;

      upstream app { server web.demo.svc.cluster.local:8080; keepalive 32; }

      # ---- Lua 初期化（CPU負荷関数とチューニング値）
      init_by_lua_block {
        local function toint(name, def)
          local v = tonumber(os.getenv(name) or ""); if not v then return def end
          return math.floor(v)
        end
        CHECK_REQ_ROUNDS = toint("CHECK_REQ_ROUNDS", 600)   -- アップロード本文 1チャンク当たりの反復回数
        CHECK_RES_ROUNDS = toint("CHECK_RES_ROUNDS", 200)   -- 応答本文 1チャンク当たりの反復回数
        -- 簡易 CPU 負荷：MD5 を rounds 回多重反復（LuaJIT でそこそこ重い）
        function _burn_md5(data, rounds)
          local h = data
          for i=1, rounds do
            h = ngx.md5(h)
          end
          return h
        end
        function _last_num(s) if not s or s=="" then return 0 end
          local m=s:match("([%d%.]+)$"); return tonumber(m) or 0 end
        end
      }

      server {
        listen 80; server_name _;

        # リクエスト開始時刻
        access_by_lua_block {
          ngx.ctx.t0 = ngx.now()
          ngx.ctx.check_ms = 0.0
        }

        # ---- 全ルート共通: 応答本文を処理するたびに“軽め”にCPU燃焼
        body_filter_by_lua_block {
          local chunk = ngx.arg[1]
          if chunk and #chunk > 0 and CHECK_RES_ROUNDS > 0 then
            local t = ngx.now()
            _burn_md5(chunk, CHECK_RES_ROUNDS)
            ngx.ctx.check_ms = (ngx.ctx.check_ms or 0) + (ngx.now()-t)*1000.0
          end
        }

        # ---- Server-Timing（ヘッダ時点）
        header_filter_by_lua_block {
          local now   = ngx.now()
          local total = now - (ngx.ctx.t0 or now)
          local c  = _last_num(ngx.var.upstream_connect_time)
          local h  = _last_num(ngx.var.upstream_header_time)
          local r  = _last_num(ngx.var.upstream_response_time)
          local conn_ms   = math.max(0, c)      * 1000.0
          local ttfb_up   = math.max(0, h - c)  * 1000.0
          local upbody_ms = math.max(0, r - h)  * 1000.0
          local upstream_ms = (c + (h-c) + (r-h)) * 1000.0
          local proxy_total = math.max(0, (total*1000.0) - upstream_ms)
          local check_ms = ngx.ctx.check_ms or 0.0  -- ※アップロード前段のチェックは access で加算

          local parts = {
            string.format("conn;dur=%.1f", conn_ms),
            string.format("ttfb_up;dur=%.1f", ttfb_up),
            string.format("upbody;dur=%.1f", upbody_ms),
            string.format("check_cpu;dur=%.1f", check_ms),
            string.format("proxy_total;dur=%.1f", proxy_total),
          }
          ngx.header["Server-Timing"] = table.concat(parts, ", ")
        }

        # ====== アップロード: 本文を読み込み→CPUチェック→本文を復元して転送 ======
        location = /upload {
          lua_need_request_body on;
          access_by_lua_block {
            ngx.req.read_body()
            local t = ngx.now()
            local data = ngx.req.get_body_data()
            local file = ngx.req.get_body_file()
            if data then
              if CHECK_REQ_ROUNDS > 0 then _burn_md5(data, CHECK_REQ_ROUNDS) end
              ngx.req.set_body_data(data)   -- 後段に渡すため復元
            elseif file then
              local f = io.open(file, "rb")
              if f then
                while true do
                  local chunk = f:read(65536); if not chunk then break end
                  if CHECK_REQ_ROUNDS > 0 then _burn_md5(chunk, CHECK_REQ_ROUNDS) end
                end
                f:close()
                ngx.req.set_body_file(file, true)
              end
            end
            ngx.ctx.check_ms = (ngx.ctx.check_ms or 0) + (ngx.now()-t)*1000.0
          }
          proxy_pass http://app;
          proxy_http_version 1.1;
          proxy_set_header Connection "";
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_set_header X-Forwarded-Proto $scheme;
        }

        # ====== その他（ダウンロード/通常ページ）はそのままプロキシ ======
        location / {
          proxy_pass http://app;
          proxy_http_version 1.1;
          proxy_set_header Connection "";
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_set_header X-Forwarded-Proto $scheme;
        }

        location = /healthz { return 200 "ok\n"; add_header Content-Type text/plain; }
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reverse-proxy-cpu
  namespace: demo
spec:
  replicas: 2
  selector: { matchLabels: { app: reverse-proxy-cpu } }
  template:
    metadata: { labels: { app: reverse-proxy-cpu } }
    spec:
      nodeSelector:
        kubernetes.io/hostname: node01   # Webはcontrolplane、プロキシはnode01 など分けてもOK
      containers:
        - name: openresty
          image: ${OR_IMAGE}
          imagePullPolicy: Always
          env:
            - { name: CHECK_REQ_ROUNDS, value: "600" }  # ↑↓調整ポイント（大きいほどCPUを使う）
            - { name: CHECK_RES_ROUNDS, value: "200" }
          ports: [ { containerPort: 80 } ]
          volumeMounts:
            - name: conf
              mountPath: /usr/local/openresty/nginx/conf/nginx.conf
              subPath: nginx.conf
          readinessProbe:
            httpGet: { path: /healthz, port: 80 }
            initialDelaySeconds: 3
            periodSeconds: 5
          livenessProbe:
            httpGet: { path: /healthz, port: 80 }
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            requests: { cpu: "100m", memory: "64Mi" }
            limits:   { cpu: "1000m", memory: "192Mi" }
      volumes:
        - name: conf
          configMap: { name: cpu-proxy-conf }
---
apiVersion: v1
kind: Service
metadata:
  name: reverse-proxy-cpu
  namespace: demo
spec:
  selector: { app: reverse-proxy-cpu }
  type: NodePort
  ports:
    - { name: http, port: 80, targetPort: 80, nodePort: 30080 }
